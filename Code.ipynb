{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ETS Myriad\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# we input the matplotlib to be able to see the graphs\n",
    "\n",
    "\n",
    "open_file1 = open('/home/usuario/ETS/TrainMyriad.csv')\n",
    "open_file2 = open('/home/usuario/ETS/TestMyriad.csv')\n",
    "TrainMyriad = pd.read_csv(open_file1)\n",
    "TestMyriad = pd.read_csv(open_file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.853288e-03</td>\n",
       "      <td>4.000000e-15</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>-0.004156</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>7.367990e-03</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014798</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>3.286691e-02</td>\n",
       "      <td>-0.009767</td>\n",
       "      <td>-0.004773</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.600000e-14</td>\n",
       "      <td>-3.401360e-03</td>\n",
       "      <td>-0.009101</td>\n",
       "      <td>-0.009185</td>\n",
       "      <td>-0.004056</td>\n",
       "      <td>-0.012798</td>\n",
       "      <td>-0.009428</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>1.119620e-02</td>\n",
       "      <td>-0.027972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002634</td>\n",
       "      <td>-0.008803</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>-8.857400e-03</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>-0.014260</td>\n",
       "      <td>-0.036166</td>\n",
       "      <td>0.049719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.113909e-02</td>\n",
       "      <td>1.375520e-04</td>\n",
       "      <td>-0.009215</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.007884</td>\n",
       "      <td>0.027721</td>\n",
       "      <td>6.809988e-03</td>\n",
       "      <td>-0.007560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>-0.028990</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>2.320159e-02</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>-0.002647</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.234414e-02</td>\n",
       "      <td>2.053991e-02</td>\n",
       "      <td>-0.092294</td>\n",
       "      <td>0.033893</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.049955</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.218855e-02</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015967</td>\n",
       "      <td>-0.004577</td>\n",
       "      <td>-0.007941</td>\n",
       "      <td>-2.110000e-15</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.002895</td>\n",
       "      <td>-0.003733</td>\n",
       "      <td>-0.021232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-3.113501e-03</td>\n",
       "      <td>-1.022147e-02</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>-0.012872</td>\n",
       "      <td>-0.005216</td>\n",
       "      <td>-0.006991</td>\n",
       "      <td>4.440000e-16</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>-8.412915e-03</td>\n",
       "      <td>0.008484</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1         2         3         4         5  \\\n",
       "0  8.853288e-03  4.000000e-15  0.005433 -0.004156  0.023372  0.006525   \n",
       "1  1.600000e-14 -3.401360e-03 -0.009101 -0.009185 -0.004056 -0.012798   \n",
       "2 -2.113909e-02  1.375520e-04 -0.009215  0.001110  0.000832  0.001663   \n",
       "3  6.234414e-02  2.053991e-02 -0.092294  0.033893  0.024203  0.049955   \n",
       "4 -3.113501e-03 -1.022147e-02  0.003155  0.011724 -0.011871 -0.012872   \n",
       "\n",
       "          6         7             8         9  ...       244       245  \\\n",
       "0 -0.008104 -0.002042  7.367990e-03 -0.002438  ... -0.014798 -0.018856   \n",
       "1 -0.009428  0.009518  1.119620e-02 -0.027972  ... -0.002634 -0.008803   \n",
       "2  0.007884  0.027721  6.809988e-03 -0.007560  ... -0.003261 -0.028990   \n",
       "3  0.027920 -0.012195 -5.218855e-02  0.055654  ... -0.015967 -0.004577   \n",
       "4 -0.005216 -0.006991  4.440000e-16  0.005867  ...  0.005744  0.000457   \n",
       "\n",
       "        246           247       248       249       250       251       252  \\\n",
       "0  0.000977  3.286691e-02 -0.009767 -0.004773  0.003197  0.005736  0.004753   \n",
       "1  0.002664 -8.857400e-03  0.008937 -0.006200 -0.014260 -0.036166  0.049719   \n",
       "2 -0.003601  2.320159e-02  0.008546  0.024517 -0.002647  0.003870  0.021809   \n",
       "3 -0.007941 -2.110000e-15  0.009480  0.009182 -0.002895 -0.003733 -0.021232   \n",
       "4  0.004339 -8.412915e-03  0.008484  0.001364  0.002044  0.004305  0.008800   \n",
       "\n",
       "   Class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 254 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainMyriad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 254 entries, 0 to Class\n",
      "dtypes: float64(253), int64(1)\n",
      "memory usage: 19.4 MB\n"
     ]
    }
   ],
   "source": [
    "TrainMyriad.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-6.535950e-03</td>\n",
       "      <td>-0.013158</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-1.612900e-02</td>\n",
       "      <td>1.311480e-02</td>\n",
       "      <td>-4.854370e-03</td>\n",
       "      <td>2.710030e-03</td>\n",
       "      <td>-0.023784</td>\n",
       "      <td>-0.003322</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>...</td>\n",
       "      <td>2.924930e-02</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>-0.006595</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>-3.757310e-02</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>-0.006319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-8.450000e-14</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>6.430870e-03</td>\n",
       "      <td>-2.555910e-02</td>\n",
       "      <td>1.670000e-14</td>\n",
       "      <td>-3.278690e-03</td>\n",
       "      <td>-0.003289</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.590000e-14</td>\n",
       "      <td>-0.011468</td>\n",
       "      <td>-0.044083</td>\n",
       "      <td>0.024272</td>\n",
       "      <td>3.317540e-02</td>\n",
       "      <td>-0.018349</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>-0.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.562420e-02</td>\n",
       "      <td>-0.008328</td>\n",
       "      <td>-0.029716</td>\n",
       "      <td>1.464710e-02</td>\n",
       "      <td>8.660000e-15</td>\n",
       "      <td>-5.905510e-03</td>\n",
       "      <td>1.716170e-02</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>...</td>\n",
       "      <td>3.206600e-03</td>\n",
       "      <td>-0.020091</td>\n",
       "      <td>-0.002330</td>\n",
       "      <td>-0.002335</td>\n",
       "      <td>4.213480e-03</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.006080</td>\n",
       "      <td>0.012235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-2.189780e-02</td>\n",
       "      <td>-0.013859</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>-3.360000e-14</td>\n",
       "      <td>3.600000e-14</td>\n",
       "      <td>-1.550000e-15</td>\n",
       "      <td>-2.110000e-15</td>\n",
       "      <td>0.098291</td>\n",
       "      <td>-0.037938</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.740740e-02</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>-0.034431</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>1.312290e-01</td>\n",
       "      <td>-0.045521</td>\n",
       "      <td>-0.016923</td>\n",
       "      <td>-0.010955</td>\n",
       "      <td>0.093354</td>\n",
       "      <td>0.031838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-2.012579e-02</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>-1.736973e-02</td>\n",
       "      <td>-3.030303e-02</td>\n",
       "      <td>1.367188e-02</td>\n",
       "      <td>7.064868e-03</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>-0.017165</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497193e-02</td>\n",
       "      <td>-0.017733</td>\n",
       "      <td>0.018053</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>-1.220000e-15</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>-0.011860</td>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>-0.001856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2             3             4             5  \\\n",
       "0 -6.535950e-03 -0.013158  0.033333 -1.612900e-02  1.311480e-02 -4.854370e-03   \n",
       "1 -8.450000e-14  0.080420  0.006472  6.430870e-03 -2.555910e-02  1.670000e-14   \n",
       "2  2.562420e-02 -0.008328 -0.029716  1.464710e-02  8.660000e-15 -5.905510e-03   \n",
       "3 -2.189780e-02 -0.013859  0.011892 -3.360000e-14  3.600000e-14 -1.550000e-15   \n",
       "4 -2.012579e-02  0.019897  0.014475 -1.736973e-02 -3.030303e-02  1.367188e-02   \n",
       "\n",
       "              6         7         8         9  ...           243       244  \\\n",
       "0  2.710030e-03 -0.023784 -0.003322  0.033889  ...  2.924930e-02  0.005368   \n",
       "1 -3.278690e-03 -0.003289  0.006601  0.019672  ... -4.590000e-14 -0.011468   \n",
       "2  1.716170e-02  0.004542  0.020026  0.015833  ...  3.206600e-03 -0.020091   \n",
       "3 -2.110000e-15  0.098291 -0.037938  0.008089  ... -4.740740e-02  0.038880   \n",
       "4  7.064868e-03  0.003189 -0.017165  0.000647  ... -1.497193e-02 -0.017733   \n",
       "\n",
       "        245       246           247       248       249       250       251  \\\n",
       "0 -0.006595  0.026557 -3.757310e-02  0.005440 -0.014322  0.018405  0.003488   \n",
       "1 -0.044083  0.024272  3.317540e-02 -0.018349  0.014019  0.016129 -0.015873   \n",
       "2 -0.002330 -0.002335  4.213480e-03 -0.003263 -0.006080  0.012235  0.000000   \n",
       "3 -0.034431 -0.066667  1.312290e-01 -0.045521 -0.016923 -0.010955  0.093354   \n",
       "4  0.018053 -0.001900 -1.220000e-15  0.016497 -0.011860  0.015161  0.005600   \n",
       "\n",
       "        252  \n",
       "0 -0.006319  \n",
       "1 -0.009217  \n",
       "2  0.015807  \n",
       "3  0.031838  \n",
       "4 -0.001856  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestMyriad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 253 entries, 0 to 252\n",
      "dtypes: float64(253)\n",
      "memory usage: 19.3 MB\n"
     ]
    }
   ],
   "source": [
    "TestMyriad.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "249      0\n",
       "250      0\n",
       "251      0\n",
       "252      0\n",
       "Class    0\n",
       "Length: 254, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainMyriad.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we can appreciate for the different formulas there are no extra information for each column. We see numbers but we don't know the information at which they are associated. \n",
    "\n",
    "All the numbers are float except for the Class column that is the column that we actually want to predict in the TestMyriad Document. They are not strange values nor missing ones.\n",
    "\n",
    "The project will be a binary classification due to the fact the only possibilities in Class are or 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(TrainMyriad['Class'], label='Sum')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph demonstrates the set is balanced as the distribution is 50% each more or less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization \n",
    "\n",
    "We do a standarization of all the columns but the Class one that we want to maintain as our binary result 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Standard_TrainMyriad = pd.DataFrame(ss.fit_transform(TrainMyriad), columns = TrainMyriad.columns)\n",
    "Standard_TrainMyriad['Class'] = TrainMyriad['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.381217</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>0.243446</td>\n",
       "      <td>-0.240912</td>\n",
       "      <td>1.087315</td>\n",
       "      <td>0.285451</td>\n",
       "      <td>-0.420432</td>\n",
       "      <td>-0.148362</td>\n",
       "      <td>0.323031</td>\n",
       "      <td>-0.145540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.736872</td>\n",
       "      <td>-0.988155</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>1.616466</td>\n",
       "      <td>-0.503686</td>\n",
       "      <td>-0.263905</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.260528</td>\n",
       "      <td>0.215106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.047454</td>\n",
       "      <td>-0.187469</td>\n",
       "      <td>-0.447653</td>\n",
       "      <td>-0.488570</td>\n",
       "      <td>-0.242282</td>\n",
       "      <td>-0.649970</td>\n",
       "      <td>-0.484250</td>\n",
       "      <td>0.418697</td>\n",
       "      <td>0.508229</td>\n",
       "      <td>-1.399531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156760</td>\n",
       "      <td>-0.486078</td>\n",
       "      <td>0.109742</td>\n",
       "      <td>-0.449182</td>\n",
       "      <td>0.400748</td>\n",
       "      <td>-0.333930</td>\n",
       "      <td>-0.704800</td>\n",
       "      <td>-1.822675</td>\n",
       "      <td>2.389024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.070996</td>\n",
       "      <td>-0.019182</td>\n",
       "      <td>-0.453047</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>-0.005352</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>0.349789</td>\n",
       "      <td>1.311545</td>\n",
       "      <td>0.296037</td>\n",
       "      <td>-0.397067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186648</td>\n",
       "      <td>-1.494303</td>\n",
       "      <td>-0.194159</td>\n",
       "      <td>1.137964</td>\n",
       "      <td>0.381864</td>\n",
       "      <td>1.172693</td>\n",
       "      <td>-0.135608</td>\n",
       "      <td>0.167751</td>\n",
       "      <td>1.039684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.971211</td>\n",
       "      <td>0.951021</td>\n",
       "      <td>-4.403596</td>\n",
       "      <td>1.633010</td>\n",
       "      <td>1.127606</td>\n",
       "      <td>2.387836</td>\n",
       "      <td>1.315069</td>\n",
       "      <td>-0.646358</td>\n",
       "      <td>-2.558134</td>\n",
       "      <td>2.707413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792608</td>\n",
       "      <td>-0.275012</td>\n",
       "      <td>-0.404671</td>\n",
       "      <td>-0.010678</td>\n",
       "      <td>0.427012</td>\n",
       "      <td>0.420537</td>\n",
       "      <td>-0.147776</td>\n",
       "      <td>-0.210229</td>\n",
       "      <td>-1.041174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.198208</td>\n",
       "      <td>-0.511789</td>\n",
       "      <td>0.135170</td>\n",
       "      <td>0.541207</td>\n",
       "      <td>-0.621146</td>\n",
       "      <td>-0.653541</td>\n",
       "      <td>-0.281306</td>\n",
       "      <td>-0.391090</td>\n",
       "      <td>-0.033410</td>\n",
       "      <td>0.262318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242792</td>\n",
       "      <td>-0.023620</td>\n",
       "      <td>0.190965</td>\n",
       "      <td>-0.427177</td>\n",
       "      <td>0.378878</td>\n",
       "      <td>0.037092</td>\n",
       "      <td>0.094268</td>\n",
       "      <td>0.189402</td>\n",
       "      <td>0.410753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.381217 -0.025723  0.243446 -0.240912  1.087315  0.285451 -0.420432   \n",
       "1 -0.047454 -0.187469 -0.447653 -0.488570 -0.242282 -0.649970 -0.484250   \n",
       "2 -1.070996 -0.019182 -0.453047  0.018476 -0.005352  0.050050  0.349789   \n",
       "3  2.971211  0.951021 -4.403596  1.633010  1.127606  2.387836  1.315069   \n",
       "4 -0.198208 -0.511789  0.135170  0.541207 -0.621146 -0.653541 -0.281306   \n",
       "\n",
       "          7         8         9  ...       244       245       246       247  \\\n",
       "0 -0.148362  0.323031 -0.145540  ... -0.736872 -0.988155  0.027913  1.616466   \n",
       "1  0.418697  0.508229 -1.399531  ... -0.156760 -0.486078  0.109742 -0.449182   \n",
       "2  1.311545  0.296037 -0.397067  ... -0.186648 -1.494303 -0.194159  1.137964   \n",
       "3 -0.646358 -2.558134  2.707413  ... -0.792608 -0.275012 -0.404671 -0.010678   \n",
       "4 -0.391090 -0.033410  0.262318  ...  0.242792 -0.023620  0.190965 -0.427177   \n",
       "\n",
       "        248       249       250       251       252  Class  \n",
       "0 -0.503686 -0.263905  0.150794  0.260528  0.215106      1  \n",
       "1  0.400748 -0.333930 -0.704800 -1.822675  2.389024      0  \n",
       "2  0.381864  1.172693 -0.135608  0.167751  1.039684      1  \n",
       "3  0.427012  0.420537 -0.147776 -0.210229 -1.041174      1  \n",
       "4  0.378878  0.037092  0.094268  0.189402  0.410753      1  \n",
       "\n",
       "[5 rows x 254 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Standard_TrainMyriad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Algorithms\n",
    "\n",
    "We can try different things to check which one can give us a best performance(Best Roc Auc Score). First we are gonna do it by what is called Brute Force that is using the whole Data Set without any dimensionality reduction. Due to the lack of information to do it by any kind of previous assesment.\n",
    "\n",
    "After that we are going to use different dimensionality reductions with different Classifiers and we will choose to use the one that has the best performance.\n",
    "\n",
    "Dimensionality reduction:\n",
    "\n",
    "    Correlation coefficient score\n",
    "    Voting classifier\n",
    "    Linear SVC + SelectFromModel\n",
    "    Linear SVC + RFECV\n",
    "    Tree-based feature selection\n",
    "\n",
    "The Classifiers:\n",
    "\n",
    "    Logistic Regression\n",
    "    Decision Tree\n",
    "    Support Vector Machine\n",
    "    Linear Discriminant Analysis\n",
    "    Quadratic Discriminant Analysis\n",
    "    Random Forest\n",
    "    K-Nearest Neighbors\n",
    "    Naive Bayes\n",
    "    \n",
    "Scoring:\n",
    "\n",
    "    Precision score\n",
    "    Recall score\n",
    "    F1 score\n",
    "    support score\n",
    "    accuracy score\n",
    "    AUC/ROC\n",
    "    \n",
    "Even if the only import parameter for the test at the end is the Roc_AUC_Score, i think is interesting to check the other values because we can use them if we want to work with the same data set but we are interested in other conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
      "       ...\n",
      "       '243', '244', '245', '246', '247', '248', '249', '250', '251', '252'],\n",
      "      dtype='object', length=253)\n"
     ]
    }
   ],
   "source": [
    "columns_features = Standard_TrainMyriad.columns\n",
    "columns_no_class = columns_features[:-1]\n",
    "print(columns_no_class)\n",
    "\n",
    "X = Standard_TrainMyriad[columns_no_class]\n",
    "y = Standard_TrainMyriad['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.049246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529609</td>\n",
       "      <td>0.533157</td>\n",
       "      <td>0.530308</td>\n",
       "      <td>0.520194</td>\n",
       "      <td>0.533384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.519613</td>\n",
       "      <td>0.524924</td>\n",
       "      <td>0.520633</td>\n",
       "      <td>0.498770</td>\n",
       "      <td>0.532593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>48.455133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516886</td>\n",
       "      <td>0.516986</td>\n",
       "      <td>0.516932</td>\n",
       "      <td>0.516537</td>\n",
       "      <td>0.522679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.664060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516445</td>\n",
       "      <td>0.516451</td>\n",
       "      <td>0.516405</td>\n",
       "      <td>0.515991</td>\n",
       "      <td>0.516405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.559434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508555</td>\n",
       "      <td>0.508216</td>\n",
       "      <td>0.507944</td>\n",
       "      <td>0.500678</td>\n",
       "      <td>0.509693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.087095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499915</td>\n",
       "      <td>0.499877</td>\n",
       "      <td>0.499876</td>\n",
       "      <td>0.499679</td>\n",
       "      <td>0.499524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.148041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500674</td>\n",
       "      <td>0.500628</td>\n",
       "      <td>0.500628</td>\n",
       "      <td>0.500427</td>\n",
       "      <td>0.499354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.029280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499773</td>\n",
       "      <td>0.500028</td>\n",
       "      <td>0.499968</td>\n",
       "      <td>0.497035</td>\n",
       "      <td>0.497924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Fitting time Scoring Time  Accuracy  \\\n",
       "4  Quadratic Discriminant Analysis      0.049246          NaN  0.529609   \n",
       "7                            Bayes      0.016361          NaN  0.519613   \n",
       "2           Support Vector Machine     48.455133          NaN  0.516886   \n",
       "1                    Decision Tree      1.664060          NaN  0.516445   \n",
       "5                    Random Forest      0.559434          NaN  0.508555   \n",
       "0              Logistic Regression      0.087095          NaN  0.499915   \n",
       "3     Linear Discriminant Analysis      0.148041          NaN  0.500674   \n",
       "6              K-Nearest Neighbors      0.029280          NaN  0.499773   \n",
       "\n",
       "   Precision    Recall  F1_score   AUC_ROC  \n",
       "4   0.533157  0.530308  0.520194  0.533384  \n",
       "7   0.524924  0.520633  0.498770  0.532593  \n",
       "2   0.516986  0.516932  0.516537  0.522679  \n",
       "1   0.516451  0.516405  0.515991  0.516405  \n",
       "5   0.508216  0.507944  0.500678  0.509693  \n",
       "0   0.499877  0.499876  0.499679  0.499524  \n",
       "3   0.500628  0.500628  0.500427  0.499354  \n",
       "6   0.500028  0.499968  0.497035  0.497924  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_initial = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time],\n",
    "    'Scoring': [LR_score_time, dtree_score_time, SVM_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time],\n",
    "    'Accuracy': [LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n",
    "    'Precision': [LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n",
    "    'Recall': [LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n",
    "    'F1_score': [LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n",
    "    'AUC_ROC': [LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n",
    "}, columns = ['Model', 'Fitting time', 'Scoring Time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_initial.sort_values(by='AUC_ROC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe in the table the results are pretty bad for the AUC_ROC because it seems like everything is random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Data columns with very similira trends carry similar information so any pair of columns with correlation higher than a threshold are reduced to only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6  \\\n",
      "0     0.381217 -0.025723  0.243446 -0.240912  1.087315  0.285451 -0.420432   \n",
      "1    -0.047454 -0.187469 -0.447653 -0.488570 -0.242282 -0.649970 -0.484250   \n",
      "2    -1.070996 -0.019182 -0.453047  0.018476 -0.005352  0.050050  0.349789   \n",
      "3     2.971211  0.951021 -4.403596  1.633010  1.127606  2.387836  1.315069   \n",
      "4    -0.198208 -0.511789  0.135170  0.541207 -0.621146 -0.653541 -0.281306   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "9995  0.082444 -1.393482 -0.178621 -1.193437 -0.045681 -0.030430  1.640633   \n",
      "9996 -0.042078  0.048192 -0.014877 -0.674975  0.210201  0.153449 -0.072919   \n",
      "9997  0.086335 -0.573684 -1.485038  0.646380  1.004613  0.213997  0.139397   \n",
      "9998 -0.039604 -0.133641  0.131910  0.051531  0.393229 -0.045943 -0.030024   \n",
      "9999 -0.485669  0.241544  0.377121  0.025210 -0.823982 -0.091716  0.336387   \n",
      "\n",
      "             7         8         9  ...       243       244       245  \\\n",
      "0    -0.148362  0.323031 -0.145540  ... -0.140157 -0.736872 -0.988155   \n",
      "1     0.418697  0.508229 -1.399531  ... -0.575110 -0.156760 -0.486078   \n",
      "2     1.311545  0.296037 -0.397067  ...  0.939045 -0.186648 -1.494303   \n",
      "3    -0.646358 -2.558134  2.707413  ...  0.198498 -0.792608 -0.275012   \n",
      "4    -0.391090 -0.033410  0.262318  ...  0.794990  0.242792 -0.023620   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "9995  0.757037  1.626904 -0.121663  ...  0.234089  0.542255 -0.417303   \n",
      "9996  0.274204 -0.204732  0.775979  ... -0.196003 -0.031154  0.372584   \n",
      "9997 -0.048176 -0.045519  0.195524  ...  0.108811 -0.120654  0.297884   \n",
      "9998 -0.221140  0.316754  0.083991  ... -0.638176 -0.068664 -0.170937   \n",
      "9999 -0.185305 -0.182596 -0.025806  ...  0.314402  0.217743 -1.198922   \n",
      "\n",
      "           246       247       248       249       250       251       252  \n",
      "0     0.027913  1.616466 -0.503686 -0.263905  0.150794  0.260528  0.215106  \n",
      "1     0.109742 -0.449182  0.400748 -0.333930 -0.704800 -1.822675  2.389024  \n",
      "2    -0.194159  1.137964  0.381864  1.172693 -0.135608  0.167751  1.039684  \n",
      "3    -0.404671 -0.010678  0.427012  0.420537 -0.147776 -0.210229 -1.041174  \n",
      "4     0.190965 -0.427177  0.378878  0.037092  0.094268  0.189402  0.410753  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "9995 -0.019485 -0.010678 -1.092587 -0.655118 -0.005891  0.026713  0.259735  \n",
      "9996 -0.385062 -0.313414  0.678816 -0.461542  0.192378  0.214746 -0.232174  \n",
      "9997 -0.019485  0.251264 -0.345787 -0.839905 -1.186135  1.605633 -0.105866  \n",
      "9998 -0.178971  0.747151 -0.226228 -0.356256 -0.501669 -0.169801  0.088284  \n",
      "9999  0.077900 -0.191574  0.277522 -0.744760 -0.917945 -0.477869 -0.346788  \n",
      "\n",
      "[10000 rows x 253 columns]\n"
     ]
    }
   ],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname]\n",
    "                    \n",
    "    print(dataset)\n",
    "\n",
    "#correlation = TrainMyriad.corr()\n",
    "\n",
    "#mask = np.zeros_like(correlation, dtype=np.bool)\n",
    "#mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "#f, ax = plt.subplots(figsize = (40,40))\n",
    "\n",
    "#cmap = sns.diverging_palette(180, 20, as_cmap=True)\n",
    "#sns.heatmap(correlation, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0, square=True, linewidths=.5, cbar_kws={'shrink': .5}, annot=True)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "correlation(X, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying to find patterns in the correlation to eliminate columns we have seen that there are no correlated columns with a threshold above 0.6 so now lets try another method to reduce the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "         DecisionTreeClassifier(),\n",
    "         SVC(probability = True),\n",
    "         LinearDiscriminantAnalysis(),\n",
    "         QuadraticDiscriminantAnalysis(),\n",
    "         RandomForestClassifier(),\n",
    "         KNeighborsClassifier(),\n",
    "         GaussianNB()]\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ens = list(zip(['LR', 'DT', 'SVM', 'LDA', 'QDA', 'RF', 'KNN', 'NB'], models))\n",
    "\n",
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'hard')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "\n",
    "acc_hard = accuracy_score(y_test, pred)\n",
    "prec_hard = precision_score(y_test, pred)\n",
    "recall_hard = recall_score(y_test, pred)\n",
    "f1_hard = f1_score(y_test, pred)\n",
    "roc_auc_hard = 'not applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "prob = model_ens.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_soft = accuracy_score(y_test, pred)\n",
    "prec_soft = precision_score(y_test, pred)\n",
    "recall_soft = recall_score(y_test, pred)\n",
    "f1_soft = f1_score(y_test, pred)\n",
    "roc_auc_soft = roc_auc_score(y_test, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.526610</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>0.596086</td>\n",
       "      <td>0.534233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ensembling_hard</td>\n",
       "      <td>0.512202</td>\n",
       "      <td>0.520102</td>\n",
       "      <td>0.473287</td>\n",
       "      <td>0.495591</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision    Recall  F1_score         AUC_ROC\n",
       "1  Ensembling_soft  0.526610   0.524735  0.689895  0.596086        0.534233\n",
       "0  Ensembling_hard  0.512202   0.520102  0.473287  0.495591  not applicable"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model': ['Ensembling_hard', 'Ensembling_soft'],\n",
    "    'Accuracy': [acc_hard, acc_soft],\n",
    "    'Precision': [prec_hard, prec_soft],\n",
    "    'Recall': [recall_hard, recall_soft],\n",
    "    'F1_score': [f1_hard, f1_soft],\n",
    "    'AUC_ROC': [roc_auc_hard, roc_auc_soft],\n",
    "}, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC + SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 253)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 101)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.05, penalty='l2', dual=False).fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_svc = model.transform(X)\n",
    "X_svc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_svc,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.044305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527207</td>\n",
       "      <td>0.527140</td>\n",
       "      <td>0.526884</td>\n",
       "      <td>0.526159</td>\n",
       "      <td>0.543393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.024349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526904</td>\n",
       "      <td>0.526832</td>\n",
       "      <td>0.526591</td>\n",
       "      <td>0.525935</td>\n",
       "      <td>0.543280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>19.485156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530255</td>\n",
       "      <td>0.530160</td>\n",
       "      <td>0.529657</td>\n",
       "      <td>0.527934</td>\n",
       "      <td>0.541481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522211</td>\n",
       "      <td>0.524602</td>\n",
       "      <td>0.520203</td>\n",
       "      <td>0.499771</td>\n",
       "      <td>0.534390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.015001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515381</td>\n",
       "      <td>0.515502</td>\n",
       "      <td>0.513808</td>\n",
       "      <td>0.501332</td>\n",
       "      <td>0.520258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.541253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515846</td>\n",
       "      <td>0.515824</td>\n",
       "      <td>0.515788</td>\n",
       "      <td>0.515473</td>\n",
       "      <td>0.515788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.368870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508599</td>\n",
       "      <td>0.509835</td>\n",
       "      <td>0.509487</td>\n",
       "      <td>0.503904</td>\n",
       "      <td>0.512606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501432</td>\n",
       "      <td>0.501039</td>\n",
       "      <td>0.500988</td>\n",
       "      <td>0.499918</td>\n",
       "      <td>0.503994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Fitting time Scoring Time  Accuracy  \\\n",
       "3     Linear Discriminant Analysis      0.044305          NaN  0.527207   \n",
       "0              Logistic Regression      0.024349          NaN  0.526904   \n",
       "2           Support Vector Machine     19.485156          NaN  0.530255   \n",
       "7                            Bayes      0.005871          NaN  0.522211   \n",
       "4  Quadratic Discriminant Analysis      0.015001          NaN  0.515381   \n",
       "1                    Decision Tree      0.541253          NaN  0.515846   \n",
       "5                    Random Forest      0.368870          NaN  0.508599   \n",
       "6              K-Nearest Neighbors      0.009942          NaN  0.501432   \n",
       "\n",
       "   Precision    Recall  F1_score   AUC_ROC  \n",
       "3   0.527140  0.526884  0.526159  0.543393  \n",
       "0   0.526832  0.526591  0.525935  0.543280  \n",
       "2   0.530160  0.529657  0.527934  0.541481  \n",
       "7   0.524602  0.520203  0.499771  0.534390  \n",
       "4   0.515502  0.513808  0.501332  0.520258  \n",
       "1   0.515824  0.515788  0.515473  0.515788  \n",
       "5   0.509835  0.509487  0.503904  0.512606  \n",
       "6   0.501039  0.500988  0.499918  0.503994  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_sfm = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time],\n",
    "    'Scoring': [LR_score_time, dtree_score_time, SVM_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time],\n",
    "    'Accuracy': [LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n",
    "    'Precision': [LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n",
    "    'Recall': [LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n",
    "    'F1_score': [LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n",
    "    'AUC_ROC': [LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n",
    "}, columns = ['Model', 'Fitting time', 'Scoring Time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_sfm.sort_values(by='AUC_ROC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC + RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.05, penalty='l2', dual=False)\n",
    "model = RFECV(estimator=lsvc, step=1, cv=20).fit(X,y)\n",
    "X_rfecv = model.transform(X)\n",
    "X_rfecv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rfecv,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523078</td>\n",
       "      <td>0.523149</td>\n",
       "      <td>0.523056</td>\n",
       "      <td>0.522596</td>\n",
       "      <td>0.527474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523078</td>\n",
       "      <td>0.523151</td>\n",
       "      <td>0.523055</td>\n",
       "      <td>0.522596</td>\n",
       "      <td>0.527474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516136</td>\n",
       "      <td>0.519414</td>\n",
       "      <td>0.515597</td>\n",
       "      <td>0.493426</td>\n",
       "      <td>0.519217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>3.516153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514315</td>\n",
       "      <td>0.514941</td>\n",
       "      <td>0.513976</td>\n",
       "      <td>0.504750</td>\n",
       "      <td>0.517343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507659</td>\n",
       "      <td>0.508853</td>\n",
       "      <td>0.507139</td>\n",
       "      <td>0.486198</td>\n",
       "      <td>0.514293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499195</td>\n",
       "      <td>0.499451</td>\n",
       "      <td>0.499461</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.499779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498734</td>\n",
       "      <td>0.498754</td>\n",
       "      <td>0.498744</td>\n",
       "      <td>0.498360</td>\n",
       "      <td>0.498864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498129</td>\n",
       "      <td>0.498149</td>\n",
       "      <td>0.498138</td>\n",
       "      <td>0.497612</td>\n",
       "      <td>0.498138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Fitting time Scoring Time  Accuracy  \\\n",
       "3     Linear Discriminant Analysis      0.003947          NaN  0.523078   \n",
       "0              Logistic Regression      0.003573          NaN  0.523078   \n",
       "7                            Bayes      0.001455          NaN  0.516136   \n",
       "2           Support Vector Machine      3.516153          NaN  0.514315   \n",
       "4  Quadratic Discriminant Analysis      0.001316          NaN  0.507659   \n",
       "5                    Random Forest      0.096859          NaN  0.499195   \n",
       "6              K-Nearest Neighbors      0.001968          NaN  0.498734   \n",
       "1                    Decision Tree      0.038940          NaN  0.498129   \n",
       "\n",
       "   Precision    Recall  F1_score   AUC_ROC  \n",
       "3   0.523149  0.523056  0.522596  0.527474  \n",
       "0   0.523151  0.523055  0.522596  0.527474  \n",
       "7   0.519414  0.515597  0.493426  0.519217  \n",
       "2   0.514941  0.513976  0.504750  0.517343  \n",
       "4   0.508853  0.507139  0.486198  0.514293  \n",
       "5   0.499451  0.499461  0.493562  0.499779  \n",
       "6   0.498754  0.498744  0.498360  0.498864  \n",
       "1   0.498149  0.498138  0.497612  0.498138  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_rfecv = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time],\n",
    "    'Scoring': [LR_score_time, dtree_score_time, SVM_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time],\n",
    "    'Accuracy': [LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n",
    "    'Precision': [LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n",
    "    'Recall': [LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n",
    "    'F1_score': [LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n",
    "    'AUC_ROC': [LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n",
    "}, columns = ['Model', 'Fitting time', 'Scoring Time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_rfecv.sort_values(by='AUC_ROC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 124)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.05, penalty = 'l2', dual = False).fit(X,y)\n",
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(X, y)\n",
    "\n",
    "model = SelectFromModel(etc, prefit=True)\n",
    "X_etc = model.transform(X)\n",
    "X_etc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_etc,y,test_size=0.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>23.478637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534648</td>\n",
       "      <td>0.534822</td>\n",
       "      <td>0.534503</td>\n",
       "      <td>0.533429</td>\n",
       "      <td>0.540868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525690</td>\n",
       "      <td>0.530365</td>\n",
       "      <td>0.524960</td>\n",
       "      <td>0.503724</td>\n",
       "      <td>0.538180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530664</td>\n",
       "      <td>0.534551</td>\n",
       "      <td>0.530052</td>\n",
       "      <td>0.515438</td>\n",
       "      <td>0.533735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.056981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514168</td>\n",
       "      <td>0.514145</td>\n",
       "      <td>0.514127</td>\n",
       "      <td>0.513768</td>\n",
       "      <td>0.520140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.030210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514171</td>\n",
       "      <td>0.514132</td>\n",
       "      <td>0.514123</td>\n",
       "      <td>0.513744</td>\n",
       "      <td>0.519982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.416988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509632</td>\n",
       "      <td>0.510762</td>\n",
       "      <td>0.510067</td>\n",
       "      <td>0.502095</td>\n",
       "      <td>0.516583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507479</td>\n",
       "      <td>0.507808</td>\n",
       "      <td>0.506927</td>\n",
       "      <td>0.494435</td>\n",
       "      <td>0.514626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.706374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502043</td>\n",
       "      <td>0.502059</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Fitting time Scoring Time  Accuracy  \\\n",
       "2           Support Vector Machine     23.478637          NaN  0.534648   \n",
       "7                            Bayes      0.007390          NaN  0.525690   \n",
       "4  Quadratic Discriminant Analysis      0.020608          NaN  0.530664   \n",
       "3     Linear Discriminant Analysis      0.056981          NaN  0.514168   \n",
       "0              Logistic Regression      0.030210          NaN  0.514171   \n",
       "5                    Random Forest      0.416988          NaN  0.509632   \n",
       "6              K-Nearest Neighbors      0.011849          NaN  0.507479   \n",
       "1                    Decision Tree      0.706374          NaN  0.502043   \n",
       "\n",
       "   Precision    Recall  F1_score   AUC_ROC  \n",
       "2   0.534822  0.534503  0.533429  0.540868  \n",
       "7   0.530365  0.524960  0.503724  0.538180  \n",
       "4   0.534551  0.530052  0.515438  0.533735  \n",
       "3   0.514145  0.514127  0.513768  0.520140  \n",
       "0   0.514132  0.514123  0.513744  0.519982  \n",
       "5   0.510762  0.510067  0.502095  0.516583  \n",
       "6   0.507808  0.506927  0.494435  0.514626  \n",
       "1   0.502059  0.502046  0.501581  0.502046  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_tree = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time],\n",
    "    'Scoring': [LR_score_time, dtree_score_time, SVM_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time],\n",
    "    'Accuracy': [LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n",
    "    'Precision': [LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n",
    "    'Recall': [LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n",
    "    'F1_score': [LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n",
    "    'AUC_ROC': [LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n",
    "}, columns = ['Model', 'Fitting time', 'Scoring Time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_tree.sort_values(by='AUC_ROC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W/out reduction</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>Linear+SFM</th>\n",
       "      <th>AUC_ROC_sfm</th>\n",
       "      <th>Linear+RFECV</th>\n",
       "      <th>AUC_ROC_RFECV</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>AUC_ROC_trees</th>\n",
       "      <th>Voting</th>\n",
       "      <th>AUC_ROC_voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.533384</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.520258</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.514293</td>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.532593</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.534390</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.519217</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.538180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.541481</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.516405</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.515788</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.498138</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.534233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.509693</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.499779</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.516583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.499524</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.543280</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.527474</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.519982</td>\n",
       "      <td>Ensembling_hard</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.499354</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.543393</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.527474</td>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.520140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.497924</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.503994</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.498864</td>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.514626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   W/out reduction   AUC_ROC                       Linear+SFM  \\\n",
       "4  Quadratic Discriminant Analysis  0.533384  Quadratic Discriminant Analysis   \n",
       "7                            Bayes  0.532593                            Bayes   \n",
       "2           Support Vector Machine  0.522679           Support Vector Machine   \n",
       "1                    Decision Tree  0.516405                    Decision Tree   \n",
       "5                    Random Forest  0.509693                    Random Forest   \n",
       "0              Logistic Regression  0.499524              Logistic Regression   \n",
       "3     Linear Discriminant Analysis  0.499354     Linear Discriminant Analysis   \n",
       "6              K-Nearest Neighbors  0.497924              K-Nearest Neighbors   \n",
       "\n",
       "   AUC_ROC_sfm                     Linear+RFECV  AUC_ROC_RFECV  \\\n",
       "4     0.520258  Quadratic Discriminant Analysis       0.514293   \n",
       "7     0.534390                            Bayes       0.519217   \n",
       "2     0.541481           Support Vector Machine       0.517343   \n",
       "1     0.515788                    Decision Tree       0.498138   \n",
       "5     0.512606                    Random Forest       0.499779   \n",
       "0     0.543280              Logistic Regression       0.527474   \n",
       "3     0.543393     Linear Discriminant Analysis       0.527474   \n",
       "6     0.503994              K-Nearest Neighbors       0.498864   \n",
       "\n",
       "                       Extra Trees  AUC_ROC_trees           Voting  \\\n",
       "4  Quadratic Discriminant Analysis       0.533735              NaN   \n",
       "7                            Bayes       0.538180              NaN   \n",
       "2           Support Vector Machine       0.540868              NaN   \n",
       "1                    Decision Tree       0.502046  Ensembling_soft   \n",
       "5                    Random Forest       0.516583              NaN   \n",
       "0              Logistic Regression       0.519982  Ensembling_hard   \n",
       "3     Linear Discriminant Analysis       0.520140              NaN   \n",
       "6              K-Nearest Neighbors       0.514626              NaN   \n",
       "\n",
       "   AUC_ROC_voting  \n",
       "4             NaN  \n",
       "7             NaN  \n",
       "2             NaN  \n",
       "1        0.534233  \n",
       "5             NaN  \n",
       "0  not applicable  \n",
       "3             NaN  \n",
       "6             NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_general = pd.concat([models_initial['Model'],models_initial['AUC_ROC'],\n",
    "                          models_sfm['Model'],models_sfm['AUC_ROC'],\n",
    "                          models_rfecv['Model'],models_rfecv['AUC_ROC'],\n",
    "                          models_tree['Model'],models_tree['AUC_ROC'],\n",
    "                          models_ensembling['Model'],models_ensembling['AUC_ROC']], axis=1)\n",
    "model_general.columns = ['W/out reduction', 'AUC_ROC', 'Linear+SFM', 'AUC_ROC_sfm', 'Linear+RFECV', 'AUC_ROC_RFECV', 'Extra Trees', 'AUC_ROC_trees', 'Voting', 'AUC_ROC_voting']\n",
    "\n",
    "model_general.sort_values(by='AUC_ROC', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the different options that we tried give us a good solution it seems that the numbers are random. The one with the best performance was de Linear Discriminant Analysis with the dimensionality reduction of the Linear + SFM\n",
    "\n",
    "As a last resource we are going to try a neural Network to see if there is any improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5022"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.34)\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150,10), random_state=1).fit(X_train,y_train)\n",
    "NN.predict(X_test)\n",
    "scores\n",
    "round(NN.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4984"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_svc,y,test_size=0.34)\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150,10), random_state=1).fit(X_train,y_train)\n",
    "NN.predict(X_test)\n",
    "round(NN.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4916"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_rfecv,y,test_size=0.34)\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150,10), random_state=1).fit(X_train,y_train)\n",
    "NN.predict(X_test)\n",
    "round(NN.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_etc,y,test_size=0.34)\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150,10), random_state=1).fit(X_train,y_train)\n",
    "NN.predict(X_test)\n",
    "round(NN.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying so many things seems that the numbers are completely random. We are going to use the model that gave us the best performance even though is not a good one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 101)\n",
      "      Class\n",
      "0         1\n",
      "1         0\n",
      "2         0\n",
      "3         1\n",
      "4         1\n",
      "...     ...\n",
      "9995      0\n",
      "9996      0\n",
      "9997      1\n",
      "9998      1\n",
      "9999      0\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "filename='SubmissionMyriad.csv'\n",
    "holdout_data = TestMyriad[columns_no_class]\n",
    "ss = StandardScaler()\n",
    "Standard_TestMyriad = pd.DataFrame(ss.fit_transform(holdout_data), columns = holdout_data.columns)\n",
    "\n",
    "X = Standard_TrainMyriad[columns_no_class]\n",
    "y = Standard_TrainMyriad['Class']\n",
    "lsvc = LinearSVC(C=0.05, penalty='l2', dual=False)\n",
    "lsvc.fit(X,y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_svc = model.transform(X)\n",
    "X2 = model.transform(Standard_TestMyriad[columns_no_class])\n",
    "print(X2.shape)\n",
    "LDA=LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_svc, y)\n",
    "predictions = LDA.predict(X2)\n",
    "\n",
    "\n",
    "submission_df = {'Class': predictions}\n",
    "submission = pd.DataFrame(submission_df)\n",
    "submission.to_csv(filename)\n",
    "\n",
    "print(submission)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
